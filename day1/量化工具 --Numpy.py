"""
Numpy是python很多科学计算与工程库的基础库，在量化数据分析中最常使用的Pandas
也是基于Numpy的封装。可以说Numpy就是量化数据分析领域中的基础数组，学会使用Numpy
是量化分析中关键的一步

Numpy底层实现中使用了C语言和Fortran语言的机制分配内存。可以理解为它的输出是一个非常大且
联系的并且由同类型数据组成的内存区域，所以可以通过Numpy来构造一个比普通列表大的多的数组，并且
灵活高效地对数组中所有的元素进行并行化操作
"""

import timeit
import time
import numpy as np
import matplotlib.pyplot as plt

"""
使用timeit模块来计算构建10000个元素的列表循环求每个元素的平方所用的时间
timeit模块使用方法 timeit(stmt,number)
stmt可以直接传简单的字符串表达式，也可以传变量，也可以传函数，接受匿名函数输入
"""

'#######################################################################################################################'

#1、使用普通方法构造列表
func1 = """
for i in range(10000):
    i**2
"""
print(timeit.timeit(stmt=func1,number=1))

#结果：0.003410174186735481
"""
或者在jupyternotebook中执行
normal_list = range(10000)
%timeit [i**2 for i in normal_list]
得到的时间为：
3.67 ms ± 67.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
"""

#2、使用numpy的arange模块来构造列表

"""
在jupyternotebook中执行下面代码，
np_list = np.arange(10000)
%timeit (np_list**2)
得到的时间为：
9.22 µs ± 24 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)


可以看到使用numpy数组的速度远快于使用普通列表的速度
Numpy数组和普通列表的操作方式也是不同的，Numpy通过广播机制作用于每一个内部元素，是一种
并行化执行的思想，普通list则作用于整体，示例如下：
"""

#注意：在numpy中*3的操作被作用于数组的每一个元素中
np_list = np.ones(5) * 3
print(np_list)
# [3. 3. 3. 3. 3.]

#普通列表则把*3操作认为是整体性操作
normal_list = [1,1,1,1,1] * 3
print(normal_list)
# <class 'list'>: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
print(len(normal_list))
# 15

'#######################################################################################################################'

#numpy的初始化操作

"""
一些numpy常用的初始化方式
"""

#1、100个0
np.zeros(100)
# array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
#        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
#        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
#        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
#        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
#        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])


#2、shape: 3行2列全是0
np.zeros((3,2))
# array([[0., 0.],
#        [0., 0.],
#        [0., 0.]])

#3、shape:3行2列全是1
np.ones((3,2))
# array([[1., 1.],
#        [1., 1.],
#        [1., 1.]])

#4、shape:x=2,y=3,z=3 值随机
np.empty((2,3,3))
#生成两个3行3列的矩阵
# array([[[0.00000000e+000, 1.54203400e-311, 0.00000000e+000],
#         [0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
#         [0.00000000e+000, 1.54205718e-311, 1.54205718e-311]],
#        [[1.54205718e-311, 1.54205718e-311, 0.00000000e+000],
#         [0.00000000e+000, 0.00000000e+000, 0.00000000e+000],
#         [0.00000000e+000, 0.00000000e+000, 0.00000000e+000]]])

#5、初始化序列与np_list一样的shape，值权为1
# np_list = [3. 3. 3. 3. 3.]
np.ones_like(np_list)
# array([1., 1., 1., 1., 1.])

#6、初始化序列与np_list一样的shape，值全为0
# np_list = [3. 3. 3. 3. 3.]
np.zeros_like(np_list)
# array([0., 0., 0., 0., 0.])

#7、得到对角线全为1的单位矩阵
np.eye(3)
# array([[1., 0., 0.],
#        [0., 1., 0.],
#        [0., 0., 1.]])

#8、通过普通列表用np.array方法来初始化得到np array
data = [[1,2,3,4],[5,6,7,8]]
arr_np = np.array(data)
# array([[1, 2, 3, 4],
#        [5, 6, 7, 8]])

#9、通过linspace()来在0~1之间等间隔生成10个元素的序列
np.linspace(0,1,10)
# array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,
#        0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])

'#######################################################################################################################'


"""
一个例子：通过np.random.standard_normal()随机生成200支股票504个交易日服从正态分布的涨跌幅数据
$两年美股交易日总数 252*2 = 504
$交易日的数量越多，股票的数量越多，生成的数据越服从正态分布
"""

#200只股票
stock_count = 200

#504个交易日
view_days = 504

#生成正态分布：均值期望 = 0,标准差 = 1的序列
stock_day_change = np.random.standard_normal((stock_count,view_days))

#打印shape(200,504) 200行 504列
print(stock_day_change.shape)
# (200, 504)

#打印第一只股票，前5个交易日的涨跌幅情况
print (stock_day_change[0:1, :5])
# [[ 0.76926566  0.26202816  1.09951781  0.41148683 -1.38644049]]

'#######################################################################################################################'

"""
经过上面的操作后，可以得到结果为200行504列的矩阵，每一行代表一只股票，每一列代表一个交易日的涨跌幅。
"""

"""
数据的转换与规整
数据进行类型转换的目的，有些时候是为了规整数据，有些时候可以通过类型转换进一步得到有用的信息。以下代码使用astype(int)将
涨跌幅转换为int后的结果，可以更清晰的发现涨跌幅数据两端的极限值，示例如下：
"""

print(stock_day_change[0:2,0:5])
print(stock_day_change[0:2,0:5].astype(int))

#输出如下：
# [[-1.16127774  0.88150936  1.00535831  0.14685506 -1.25436484]
#  [ 0.40657144  0.48875463 -1.48877665  0.48752567 -0.7245854 ]]
# [[-1  0  1  0 -1]
#  [ 0  0 -1  0  0]]
# 如果只是想要规整float的数据，如果保留两位小数，可以使用np.around()函数，示例如下：

#保留2位小数
np.around(stock_day_change[0:2,0:5],2)

# 输出如下：
# array([[-1.16,  0.88,  1.01,  0.15, -1.25],
#        [ 0.41,  0.49, -1.49,  0.49, -0.72]])

# 很多时候需要处理的数据会有缺失，numpy中np.nan代表缺失，这里手工使切片中的第一元素变为na，代码如下：

#使用copy()函数的目的是不修改原始序列
tmp_test = stock_day_change[0:2,0:5].copy()

#将第一个元素改成nan
tmp_test[0][0] = np.nan
print(tmp_test)
# [[        nan  0.88150936  1.00535831  0.14685506 -1.25436484]
#  [ 0.40657144  0.48875463 -1.48877665  0.48752567 -0.7245854 ]]

#使用np.nan_to_num()函数来用0来填充na，由于pandas中的dropna()和fillna()等方式更适合处理nan，示例如下
tmp_test = np.nan_to_num(tmp_test)
print(tmp_test)
# [[ 0.          0.88150936  1.00535831  0.14685506 -1.25436484]
#  [ 0.40657144  0.48875463 -1.48877665  0.48752567 -0.7245854 ]]

'#######################################################################################################################'

"""
逻辑条件进行数据筛选
"""

#找出切片内涨幅超过0.5的股票时段，通过输出结果可以看到返回的mask是bool的数组，示例如下

mask = stock_day_change[0:2,0:5] > 0.5
print(mask)
# [[False  True  True False False]
#  [False False False False False]]

# mask的使用方法：
print(tmp_test[mask])
# array([0.88150936, 1.00535831])

# 其他使用方法
tmp_test = stock_day_change[-2:,-5:]
print(tmp_test[(tmp_test>1) | (tmp_test<-1)])
# [-1.22873737  2.07497224]

tmp_test[(tmp_test>1) | (tmp_test<-1)] = 1
print(tmp_test)
# [[-0.4053339   0.25982894  0.3546099  -0.62828459  0.21791254]
#  [ 1.          1.          0.24547128 -0.34095098 -0.17635608]]

'#######################################################################################################################'
"""
通用序列函数
"""


'#######################################################################################################################'

"""
基础统计概念与函数使用
量化中很多技术手段都是基于统计技术实现的，Numpy给python带来的不仅只有序列化并行执行的思想，更有统计学上很多方法的实现，比如期望(np.mean())、
方差(np.var())、标准差(np.std())等，下面说明一些Numpy中使用的统计相关的函数


"""
stock_day_change_four = stock_day_change[:4,:4]
print(stock_day_change_four)
# [[-1.16127774  0.88150936  1.00535831  0.14685506]
#  [ 0.40657144  0.48875463 -1.48877665  0.48752567]
#  [-1.50655395 -1.7205798  -1.03894972  1.27652508]
#  [-0.94481997  1.62701559  1.83180435 -0.23140463]]

#axis = 1 为行向比较 axis = 0为列向比较
print('最大涨幅{}'.format(np.max(stock_day_change_four,axis=1)))
# 最大涨幅[1.00535831 0.48875463 1.27652508 1.83180435]

'#######################################################################################################################'
"""
基础统计概念：
1、期望：试验中每次可能结果的概率乘以其结果的总和，反映一组数据平均取值的大小，用于表示分布的中心位置
2、方差：在概率论和统计学中，方差是衡量一组数据离散程度的度量，概率论中方差用来度量数据和其期望之间的离散程度，方差越大，说明数据越离散
3、标准差：标准差是方差的平方根，标准差和变量的计算单位相同，所以比其测得的误差结果比方差清晰，因此很多时候分析离散程度更多的使用标准差
"""

"""
示例如下：
如果有a、b两个交易者，他们多次交易的平均战果都是赚100元，那么他们两个人的期望都是100，但是a交易者获利的稳定性不好，假设振幅为50即标准差为50，
b交易者获利的稳定性比a好，假设振幅为20，即标准差为20
"""

a_investor = np.random.normal(loc=100,scale=50,size=(100,1))
#生成期望为100，标准差为50的服从正态分布的100个数据
b_investor = np.random.normal(loc=100,scale=20,size=(100,1))
#生成期望为100，标准差为20的服从正态分布的100个数据

print ('a交易者期望{0:.2f}元，标准差{1:.2f}，方差{2:.2f}'.format(a_investor.mean(),a_investor.std(),a_investor.var()))
# a交易者期望104.20元，标准差44.40，方差1971.43
print ('b交易者期望{0:.2f}元，标准差{1:.2f}，方差{2:.2f}'.format(b_investor.mean(),b_investor.std(),b_investor.var()))
# b交易者期望96.31元，标准差19.15，方差366.64
#注意：这里之期望不等于100，标准差不等于50是因为数据只有100个，数据越多越接近初始值

"""
下面可视化一下a、b两位交易者的获利图，图中3条直线分表代表：
1、均值获利期望线
2、均值获利期望线 + 获利标准差
3、均值获利期望线 - 获利标准差
"""

#a交易者期望
a_mean = a_investor.mean()
#a交易者标准差
a_std = a_investor.std()
#收益绘制曲线
plt.plot(a_investor)
#绘制3条直线
plt.axhline(a_mean,color='y')
plt.axhline(a_mean+a_std,color='r')
plt.axhline(a_mean-a_std,color='g')
#得到的结果如numpy-1中所示
#b交易者期望
b_mean = b_investor.mean()
#b交易者标准差
b_std = b_investor.std()
#收益绘制曲线
plt.plot(b_investor)
#绘制3条直线
plt.axhline(b_mean,color='y')
plt.axhline(b_mean+a_std,color='r')
plt.axhline(b_mean-a_std,color='g')
#得到的结果如numpy-2中所示

'#######################################################################################################################'

"""
正态分布
正态分布的特点：
对于正态分布，数据的标准差越大，数据分布离散程度越大
对于正态分布，数据的期望位于曲线的对称轴中心
下面继续使用 stock_day_change = np.random.standard_normal((stock_cnt,view_days))生成的股票数据作为示例
"""


# stock_day_change=np.random.standard_normal((200,504))
import scipy.stats as scs
#均值期望
stock_mean = stock_day_change[0].mean()
#标准差
stock_std = stock_day_change[0].std()
print('股票0 mean 均值期望:{:.3f}'.format(stock_mean))
print('股票0 std 振幅标准差:{:.3f}'.format(stock_std))
#绘制股票0的直方图
#bins--->设置分组的个数 normed--->是否对y轴数据进行标准化
plt.hist(stock_day_change[0],bins=50,normed=True)
#linspace从股票0的最小值------>到最大值生成数据 linspace默认生成50个数据
fit_linespace = np.linspace(stock_day_change[0].min(),stock_day_change[0].max())
#概率密度函数(PDF,probability density function)
#由均值、方差来描述曲线，使用scipy.stats.norm.pdf生成拟合曲线
pdf = scs.norm(stock_mean,stock_std).pdf(fit_linespace)
#plot x=fit_linspace y= pdf
plt.plot(fit_linespace,pdf,lw=2,c='r')
#结果如图numpy-3所示

'#######################################################################################################################'

"""
实例1：正态分布买入策略
继续使用之前生成的200只股票504天的服从正态分布的涨跌数据，保留后50天的随机数据作为策略的验证数据，统计前454天中跌幅最大的3只股票，假设在第454天
买入这3只股票，下面是得到的结果：
*np.sort() 针对序列进行排序
*np.argsort() 展示排序的原序列号
"""
#保留后50天的随机数据作为策略验证数据
keep_days = 50
#统计前454天中的200只股票的涨跌数据，切片切除0-454天， view_days = 504
view_days = 504
stock_cnt = 200
stock_day_change_test = stock_day_change[:stock_cnt,0:view_days - keep_days]
#打印出前454天跌幅最大的3只股票，总跌幅通过np.sum()函数设计，np.sort()函数对结果排序
#对切片的理解 [参数1:参数2 , 参数3:参数4] 左边是对行的切片，右边是对列的切片， 参数1和参数3不写默认为0 参数2不写默认为行的最大值，参数4不写默认为列的最大值
print(np.sort(np.sum(stock_day_change_test,axis=1))[:3])
# array([-65.93157728, -47.37939716, -44.7361247 ])
#使用np.argsort()函数针对股票跌幅进行排序，返回序号，即返回符合买入条件的股票序号
stock_lower_array = np.argsort(np.sum(stock_day_change_test,axis=1))[:3]
# array([138, 100, 165], dtype=int64)

"""
最后得到的结果：
array([-65.93157728, -47.37939716, -44.7361247 ])
array([138, 100, 165], dtype=int64)
即跌幅最大的三只股票的序号是第138只，第100只，第165只

下面通过构造函数show_buy_lower()可视化选中的前3只跌幅最大的股票前454日的走势，以及从第454日买入后的走势：
"""
def show_buy_lower(stock_ind):
    """
    :param stock_ind: 股票序号，即在stock_day_change中行的位置
    :return:
    """
    #设置一个一行两列的可视化图标
    _,axs = plt.subplots(nrows=1,ncols=2,figsize=(16,5))
    #绘制前454天的股票走势图，np.cumsum():序列连续求和
    axs[0].plot(np.arange(0,view_days-keep_days),stock_day_change_test[stock_ind].cumsum())
    #绘制从第454天开始到504天中股票走势
    cs_buy = stock_day_change[stock_ind][view_days-keep_days:view_days].cumsum()
    #绘制从第454天到504天中股票走势图
    axs[1].plot(np.arange(view_days-keep_days,view_days),cs_buy)
    #返回从第454天开始到504天计算盈亏序列的最后一个值
    return cs_buy[-1]

#等权重的买入3只股票
profit = 0
#遍历跌幅最大的3只股票序号序列
for stock_ind in stock_lower_array:
    #profit即3只股票从第454天买入开始计算，直到最后一天的盈亏比例
    profit += show_buy_lower(stock_ind)

#str.format 支持{:.2f}形式保留两位小数
print('买入第{}只股票，从第454个交易日开始持有盈亏:{:.2f}%'.format(stock_lower_array,profit))
"""
得到的结果为：
[-64.34276711 -46.96916996 -41.00063126]
买入第[ 76 170   8]只股票，从第454个交易日开始持有盈亏:12.31%
曲线如图numpy-4所示
这个策略之所以能够盈利，是由于通过np.random.standard_normal()建立的服从正态分布的涨跌幅数据，这样通过买入前454天中跌幅最大的3只股票的
理论依据就是按照正态分布理论，这3只股票后期的涨跌分布一定是涨的概率大于跌得概率
注意：这里并不能一定保证收益为正，产生这个的原因是第3只股票的收益一般都为负数，所以减小到2只股票甚至1只股票即能够保证总收益为正数
其中只选1只股票得到收益为正的概率最大
"""

'#######################################################################################################################'

"""
伯努利分布也是在量化分析中频繁使用的分布
伯努利分布：
伯努利分布是很简单的离散分布，在伯努利分布下，随机变量只有两个可能的取值：1和0
如果随机变量取值为1的概率为p，则随机变量取值为0的概率为1-p
在numpy中使用numpy.random.binomial(1,p)来获取1的概率为p的前提下，生成的随机变量。如果p=0.5的话，那么就类似于投掷硬币的结果，
即正面在上和反面在上的概率相同，实例如下：
"""


"""
实例：如何在交易中获取优势：
在交易中，交易者永远是处于不利地位的，不利的情况就是需要交手续费，
"""









