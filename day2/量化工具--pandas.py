"""
pandas在python金融数据分析、量化交易等领域起到了至关重要的作用，pandas的两大主要工具Dataframe和Series的框架设计
与API参考方向都是来源于统计分析语言R
"""
'#######################################################################################################################'
"""
基本操作方法
import pandas as pd
"""
import pandas as pd
import numpy as np
"""
DataFrame的构建及方法
为何需要在有numpy的情况下使用pandas，下面还是使用stock_day_change = np.random.standard_normal((200,504))生成的数据作为示例
"""
stock_day_change = np.random.standard_normal((200,504))
print(stock_day_change.shape)
# (200, 504)
#使用np.argmax()纵向寻找某日涨幅最大的股票
print(np.argmax(stock_day_change[:200,0:1],axis=0))
# [27]  第一日涨幅最大的股票是第27只股票
"""
可见，使用np.argmax()得到的结果时一个数字序列，如果要对应到股票，还需要一个字典，记录股票代码的对应关系，使用pandas就能很好的解决这个问题
首先构建一个DataFrame对象，只传入numpy对象stock_day_change,使用head()方法显示生成的表格对象的前5行数据，head方法的默认参数是5，
head()函数接受int类型数据，如果要显示前10行数据可以使用head(10)，与head方法对应的是tail方法，该方法是从表格尾部倒数5行数据
备注：pandas是在numpy的基础上构建的，所以numpy的很多使用方式以及numpy很多通用函数都是可以直接在pandas对象上直接使用，
比如head(5)可以用切片[:5]表示，tail(5)可以用切片[-5：]
"""
#下面3种方法得到的结果
pd.DataFrame(stock_day_change).head()
pd.DataFrame(stock_day_change).head(5)
pd.DataFrame(stock_day_change)[:5] #pycharm显示出可能有错误，实际运行还是可以运行的
#         0         1         2         3         4         5         6    \
# 0  1.763763  0.633713  0.052646 -0.307430  2.170177 -0.522869 -2.328716
# 1 -0.493013  1.544293  1.283240 -0.169545  0.788399 -1.301240  1.642817
# 2 -0.735805 -1.344368  1.892825 -1.056959  1.096355 -1.009330 -0.622361
# 3  0.647074  1.505698  1.685484  0.167423  0.990752  0.809298 -1.472412
# 4 -0.446379 -0.668422  0.102803 -0.008041  0.841974  0.106965 -0.943789
#         7         8         9      ...          494       495       496  \
# 0  0.566261 -0.741045  1.173815    ...    -1.185655 -0.761970 -0.446359
# 1 -0.402900 -0.034009 -1.512654    ...    -0.108322  0.287227 -0.583854
# 2 -0.963036  0.238672  1.388212    ...     0.381771  2.384015  0.311901
# 3  0.411077  1.012824 -0.285239    ...     0.550487 -0.106339  0.814421
# 4  0.940395 -0.334915  1.534626    ...    -0.811294 -0.063776  0.319897
#         497       498       499       500       501       502       503
# 0 -0.396360 -0.177785  0.705284 -0.990485  0.990421 -0.143142 -1.182432
# 1  0.921854 -0.537272 -0.922432 -1.536637  0.024564  0.042667 -1.585386
# 2 -0.074258 -0.511951  0.630515  1.514672  1.741940  0.677269  0.580679
# 3  1.546657 -1.308731 -0.600070  0.549477 -0.298747 -0.502661  1.461937
# 4  0.798141 -0.640182 -1.012756  0.715566 -0.528671  0.218613  2.476508
# [5 rows x 504 columns]
'#######################################################################################################################'
"""
索引行列序列
下面的代码使用股票0、股票1...作为股票的行索引
"""
#股票0--->股票 + stock_day_change.shape[0] shape[0]矩阵行数  stock_day_change.shape[0] = 200
stock_symbols = ['股票' + str(x) for x in range(stock_day_change.shape[0])]
#通过构造直接设置index参数，得到想要的结果：
pd.DataFrame(stock_day_change,index=stock_symbols).head()
#           0         1         2         3         4         5         6    \
# 股票0  1.763763  0.633713  0.052646 -0.307430  2.170177 -0.522869 -2.328716
# 股票1 -0.493013  1.544293  1.283240 -0.169545  0.788399 -1.301240  1.642817
# 股票2 -0.735805 -1.344368  1.892825 -1.056959  1.096355 -1.009330 -0.622361
# 股票3  0.647074  1.505698  1.685484  0.167423  0.990752  0.809298 -1.472412
# 股票4 -0.446379 -0.668422  0.102803 -0.008041  0.841974  0.106965 -0.943789
#           7         8         9      ...          494       495       496  \
# 股票0  0.566261 -0.741045  1.173815    ...    -1.185655 -0.761970 -0.446359
# 股票1 -0.402900 -0.034009 -1.512654    ...    -0.108322  0.287227 -0.583854
# 股票2 -0.963036  0.238672  1.388212    ...     0.381771  2.384015  0.311901
# 股票3  0.411077  1.012824 -0.285239    ...     0.550487 -0.106339  0.814421
# 股票4  0.940395 -0.334915  1.534626    ...    -0.811294 -0.063776  0.319897
#           497       498       499       500       501       502       503
# 股票0 -0.396360 -0.177785  0.705284 -0.990485  0.990421 -0.143142 -1.182432
# 股票1  0.921854 -0.537272 -0.922432 -1.536637  0.024564  0.042667 -1.585386
# 股票2 -0.074258 -0.511951  0.630515  1.514672  1.741940  0.677269  0.580679
# 股票3  1.546657 -1.308731 -0.600070  0.549477 -0.298747 -0.502661  1.461937
# 股票4  0.798141 -0.640182 -1.012756  0.715566 -0.528671  0.218613  2.476508
# [5 rows x 504 columns]

"""
使用pd.date_range()函数生成一组连续的时间序列，使用生成的序列作为DataFrame的列索引，从而将每个交易日表示出来，
通过columns参数传入时间序列初始化DataFrame对象
"""
#从2018-1-1向上时间递增，单位freq = '1d' 即1天
days = pd.date_range('2018-1-1',periods=stock_day_change.shape[1],freq='1d')
#从股票0 到 股票stock_day_change.shape[0]
stock_symbols = ['股票'+ str(x) for x in range(stock_day_change.shape[0])]
#分别设置index和columns
df = pd.DataFrame(stock_day_change,index=stock_symbols,columns=days)
print(df.head())
#      2018-01-01  2018-01-02  2018-01-03  2018-01-04  2018-01-05  2018-01-06  \
# 股票0    1.763763    0.633713    0.052646   -0.307430    2.170177   -0.522869
# 股票1   -0.493013    1.544293    1.283240   -0.169545    0.788399   -1.301240
# 股票2   -0.735805   -1.344368    1.892825   -1.056959    1.096355   -1.009330
# 股票3    0.647074    1.505698    1.685484    0.167423    0.990752    0.809298
# 股票4   -0.446379   -0.668422    0.102803   -0.008041    0.841974    0.106965
#      2018-01-07  2018-01-08  2018-01-09  2018-01-10     ...      2019-05-10  \
# 股票0   -2.328716    0.566261   -0.741045    1.173815     ...       -1.185655
# 股票1    1.642817   -0.402900   -0.034009   -1.512654     ...       -0.108322
# 股票2   -0.622361   -0.963036    0.238672    1.388212     ...        0.381771
# 股票3   -1.472412    0.411077    1.012824   -0.285239     ...        0.550487
# 股票4   -0.943789    0.940395   -0.334915    1.534626     ...       -0.811294
#      2019-05-11  2019-05-12  2019-05-13  2019-05-14  2019-05-15  2019-05-16  \
# 股票0   -0.761970   -0.446359   -0.396360   -0.177785    0.705284   -0.990485
# 股票1    0.287227   -0.583854    0.921854   -0.537272   -0.922432   -1.536637
# 股票2    2.384015    0.311901   -0.074258   -0.511951    0.630515    1.514672
# 股票3   -0.106339    0.814421    1.546657   -1.308731   -0.600070    0.549477
# 股票4   -0.063776    0.319897    0.798141   -0.640182   -1.012756    0.715566
#      2019-05-17  2019-05-18  2019-05-19
# 股票0    0.990421   -0.143142   -1.182432
# 股票1    0.024564    0.042667   -1.585386
# 股票2    1.741940    0.677269    0.580679
# 股票3   -0.298747   -0.502661    1.461937
# 股票4   -0.528671    0.218613    2.476508
# [5 rows x 504 columns]
'#######################################################################################################################'
"""
金融时间序列
在量化分析中最常见的数据类型是金融时间序列，对于时间序列，pandas拥有非常丰富友好的方法来分析挖掘数据
下面的代码首先将上面产生的数据df进行转置，得到行索引为时间，列索引为股票代码的金融时间序列
"""
#df做转置
df = df.T
print(df.head())
#                  股票0       股票1       股票2       股票3       股票4       股票5  \
# 2018-01-01  1.763763 -0.493013 -0.735805  0.647074 -0.446379  0.493033
# 2018-01-02  0.633713  1.544293 -1.344368  1.505698 -0.668422  1.479697
# 2018-01-03  0.052646  1.283240  1.892825  1.685484  0.102803 -0.790151
# 2018-01-04 -0.307430 -0.169545 -1.056959  0.167423 -0.008041 -1.004184
# 2018-01-05  2.170177  0.788399  1.096355  0.990752  0.841974 -0.201706
#                  股票6       股票7       股票8       股票9    ...        股票190  \
# 2018-01-01 -0.561090  0.693470  0.232592  1.792846    ...     1.666315
# 2018-01-02  1.865531 -1.136771 -0.116075  0.355855    ...    -0.634095
# 2018-01-03  0.522186 -0.924988 -0.467905 -2.170416    ...    -0.964474
# 2018-01-04 -0.239361 -0.258797  0.584921 -2.936432    ...    -0.503132
# 2018-01-05 -2.118477 -0.946267  0.211309  0.025931    ...    -0.710216
#                股票191     股票192     股票193     股票194     股票195     股票196  \
# 2018-01-01 -0.564087  0.044085  0.956755 -0.445319  0.270248 -0.663559
# 2018-01-02  0.405217  0.401289 -0.154160  0.982657  1.529452  0.402718
# 2018-01-03 -0.874172 -0.017873 -0.814189 -1.764988 -0.057031 -0.183578
# 2018-01-04 -0.259635 -1.428084  1.629341  1.154951 -2.143945  1.295296
# 2018-01-05  1.710935  1.306455 -0.121977  1.757014  0.435819 -1.662520
#                股票197     股票198     股票199
# 2018-01-01 -1.487906  0.167369 -0.039863
# 2018-01-02 -2.621317  1.655636  1.603773
# 2018-01-03  0.358838  0.684343  2.608242
# 2018-01-04 -0.652166 -1.431402 -1.789721
# 2018-01-05 -0.274267 -2.496562  0.173070
# [5 rows x 200 columns]

#以21天为周期，对21天内的时间求平均值来重新塑造数据
df_20 = df.resample('21D',how='mean')
print(df_20.head())
#21天重采样输出结果如下：
#                  股票0       股票1       股票2       股票3       股票4       股票5  \
# 2018-01-01  0.503547  0.165540  0.109003  0.124616  0.113271 -0.091469
# 2018-01-22  0.311830 -0.228215 -0.086653 -0.255172  0.124406  0.306840
# 2018-02-12 -0.010761 -0.217412 -0.193369  0.201618  0.038180  0.017662
# 2018-03-05  0.347938 -0.215381 -0.005751 -0.414531 -0.238416 -0.323266
# 2018-03-26 -0.137351  0.492963  0.339714 -0.129570 -0.240378 -0.280249
#                  股票6       股票7       股票8       股票9    ...        股票190  \
# 2018-01-01 -0.118230 -0.191800 -0.332222 -0.148708    ...     0.340622
# 2018-01-22 -0.331355  0.133854  0.229072 -0.016704    ...     0.053711
# 2018-02-12  0.107841  0.020637 -0.126360 -0.056199    ...    -0.263739
# 2018-03-05 -0.013782 -0.295839  0.166248 -0.118617    ...    -0.072564
# 2018-03-26 -0.126257 -0.160734 -0.080176  0.012015    ...    -0.351940
#                股票191     股票192     股票193     股票194     股票195     股票196  \
# 2018-01-01  0.042505 -0.285554  0.359656 -0.036770  0.083729 -0.135298
# 2018-01-22 -0.348736 -0.191161  0.326739 -0.098958  0.253385  0.262433
# 2018-02-12  0.023269  0.031774 -0.017535 -0.176792  0.118554  0.176709
# 2018-03-05 -0.041279  0.242864 -0.219726 -0.008742 -0.117881  0.002691
# 2018-03-26  0.244124  0.177961  0.106854 -0.167626  0.090076  0.073779
#                股票197     股票198     股票199
# 2018-01-01 -0.112697  0.132346 -0.098886
# 2018-01-22  0.278182  0.498828  0.372278
# 2018-02-12 -0.356313 -0.121170 -0.200282
# 2018-03-05 -0.144233 -0.319892 -0.118376
# 2018-03-26  0.034117 -0.202357  0.152384
# [5 rows x 200 columns]
'#######################################################################################################################'

"""
Series构建及方法
使用上面一个股票的时间序列数据，可以直接通过索引df['股票0']的方式得到股票0的时间序列涨跌幅，通过type()来查看返回类型，发现返回的是Series类型：
"""
df_stock0 = df['股票0']
print(df_stock0.head())
# 2018-01-01   -1.303374
# 2018-01-02   -0.288689
# 2018-01-03   -0.206059
# 2018-01-04    0.129472
# 2018-01-05    0.378317
# Freq: D, Name: 股票0, dtype: float64
#打印df_stock0类型
print(type(df_stock0))
# <class 'pandas.core.series.Series'>
# 选取行的时候使用的则是loc方法
df_stock_2018_1_1 = df.loc['2018-01-01']
print(df_stock_2018_1_1.head())
print(type(df_stock_2018_1_1))
# 股票0    0.103502
# 股票1    2.113965
# 股票2   -0.533838
# 股票3   -0.312308
# 股票4   -0.953813
# Name: 2018-01-01 00:00:00, dtype: float64
# <class 'pandas.core.series.Series'>
"""
Series是pandas中另一个非常重要的类，可以简单理解Series是只有一列数据的DataFrame对象,两者之间大多数的函数都是可以通用的，使用方法也很类似，
比如head()方法
"""
#通过cumsum()方法构造新的时间序列
#Cumsum():计算轴向元素累加和，返回由中间结果组成的数组
print(df_stock0.cumsum())
# 2018-01-01     0.103502
# 2018-01-02    -1.471346
# 2018-01-03    -1.789155
# 2018-01-04    -1.524793
# 2018-01-05    -1.877629
# 2018-01-06    -2.181606
# 2018-01-07    -1.624760
# 2018-01-08    -2.276715
# 2018-01-09    -4.101369
# 2018-01-10    -4.799449
# 2018-01-11    -4.854356
# 2018-01-12    -4.161421
# 2018-01-13    -4.635588
# 2018-01-14    -5.936918
# 2018-01-15    -6.623405
# 2018-01-16    -6.890551
# 2018-01-17    -6.091618
# 2018-01-18    -6.278310
# 2018-01-19    -6.872241
# 2018-01-20    -6.827189
# 2018-01-21    -5.682790
# 2018-01-22    -7.296769
# 2018-01-23    -7.915341
# 2018-01-24    -8.021937
# 2018-01-25    -7.980051
# 2018-01-26    -7.180001
# 2018-01-27    -5.698846
# 2018-01-28    -4.649841
# 2018-01-29    -4.404283
# 2018-01-30    -4.104647
#                 ...
# 2019-04-20   -23.710142
# 2019-04-21   -22.843026
# 2019-04-22   -22.616284
# 2019-04-23   -24.296622
# 2019-04-24   -24.479337
# 2019-04-25   -23.260574
# 2019-04-26   -23.467795
# 2019-04-27   -23.807708
# 2019-04-28   -23.642757
# 2019-04-29   -24.631327
# 2019-04-30   -25.698805
# 2019-05-01   -25.516924
# 2019-05-02   -26.786641
# 2019-05-03   -26.735161
# 2019-05-04   -26.671541
# 2019-05-05   -28.669948
# 2019-05-06   -28.463618
# 2019-05-07   -28.593521
# 2019-05-08   -27.124877
# 2019-05-09   -27.928312
# 2019-05-10   -29.991556
# 2019-05-11   -30.801532
# 2019-05-12   -30.356792
# 2019-05-13   -30.057896
# 2019-05-14   -29.942747
# 2019-05-15   -28.829870
# 2019-05-16   -27.767138
# 2019-05-17   -28.305728
# 2019-05-18   -29.766230
# 2019-05-19   -28.671890

df_stock0.cumsum().plot()
#得到股票的累计涨跌幅波动图，即股票涨跌走势图（想象连续两个涨停的情况）：结果如图pandas-1中所示
'#######################################################################################################################'

"""
重采样数据：
上文提到了resample()重采样函数，所有股票网站都提供了日K线，周k线、月k线等周期数据，但是最原始的数据只有日k线数据
下面的代码通过重采样实现周k线，月k线的构建。刚刚构建使用的how参数是mean，下面的代码通过how=ohlc，它代表周期的open，high，low和close值
，所以结果从一个列变成了有4列数据的DataFrame
"""

###？？？为何要用cumsum函数，这里面的逻辑需要整理一下（想象两个连续涨停的情况）
#以5天为周期重采样（周k）
df_stock5 = df_stock0.cumsum().resample('5D',how='ohlc')
#新写法：
# df_stock5 = df_stock0.cumsum().resample('5D').ohlc()
#以21天为周期重采样
df_stock20 = df_stock0.cumsum().resample('20D',how='ohlc')
#打印5天的重采样结果：
print(df_stock5.head())
#                 open      high       low     close
# 2018-01-01  0.103502  0.103502 -1.877629 -1.877629
# 2018-01-06 -2.181606 -1.624760 -4.799449 -4.799449
# 2018-01-11 -4.854356 -4.161421 -6.623405 -6.623405
# 2018-01-16 -6.890551 -6.091618 -6.890551 -6.827189
# 2018-01-21 -5.682790 -5.682790 -8.021937 -7.980051

"""
下面的代码使用abu量化系统中的ABuMarketDrawing.plot_candle_stick()方法，将数据的高开低收K线图绘制出来，
从而得到从日线级别的数据重新构建出轴线的数据，并且可视化
*注意下面K线线图的volum成交量通过np.random.random(len(df_stock5))生成的随机数据进行填充
*k线图的绘制将在数据可视化章节中详细的说明
"""
from abupy import ABuMarketDrawing
ABuMarketDrawing.plot_candle_stick(df_stock5.index,df_stock5['open'].values,df_stock5['high'].values,df_stock5['low'].values,df_stock5['close'].values,np.random.random(len(df_stock5)),None,'stock',day_sum=False,html_bk=False,save=False)
#结果如图pandas-2所示，类似的可以得到月k线
ABuMarketDrawing.plot_candle_stick(df_stock20.index,df_stock20['open'].values,df_stock20['high'].values,df_stock20['low'].values,df_stock20['close'].values,np.random.random(len(df_stock20)),None,'stock',day_sum=False,html_bk=False,save=False)
#结果如图pandas-3所示
"""
Series对象的values属性是一个numpy对象，而DataFrame对象的行索引属性为index，列属性为columns，如下列代码的结果所示：
"""
print(type(df_stock5['open']))
# <class 'pandas.core.series.Series'> 一个Series对象
print(type(df_stock5['open'].values))
# <class 'numpy.ndarray'> 一个numpy的ndarray对象
print(df_stock5['open'].index)
# DatetimeIndex(['2018-01-01', '2018-01-06', '2018-01-11', '2018-01-16',
#                '2018-01-21', '2018-01-26', '2018-01-31', '2018-02-05',
#                '2018-02-10', '2018-02-15',
#                ...
#                '2019-04-01', '2019-04-06', '2019-04-11', '2019-04-16',
#                '2019-04-21', '2019-04-26', '2019-05-01', '2019-05-06',
#                '2019-05-11', '2019-05-16'],
#               dtype='datetime64[ns]', length=101, freq=None) 行属性
print(df_stock5.loc['2018-01-01'])
# open     0.1035
# high     0.1035
# low     -1.8776
# close   -1.8776
# Name: 2018-01-01 00:00:00, dtype: float64  得到一行的值
print(df_stock5.loc['2018-01-01'].index)
# Index(['open', 'high', 'low', 'close'], dtype='object')
print(type(df_stock5.loc['2018-01-01']))
# <class 'pandas.core.series.Series'> 得到一个Series对象
print(df_stock5.index)
# DatetimeIndex(['2018-01-01', '2018-01-06', '2018-01-11', '2018-01-16',
#                '2018-01-21', '2018-01-26', '2018-01-31', '2018-02-05',
#                '2018-02-10', '2018-02-15',
#                ...
#                '2019-04-01', '2019-04-06', '2019-04-11', '2019-04-16',
#                '2019-04-21', '2019-04-26', '2019-05-01', '2019-05-06',
#                '2019-05-11', '2019-05-16'],
#               dtype='datetime64[ns]', length=101, freq=None)
print(type(df_stock5))
# <class 'pandas.core.frame.DataFrame'> 一个DataFrame对象
print(df_stock5.columns)
# <class 'pandas.core.frame.DataFrame'> 只有DataFrame对象有columns属性，Series只有index属性，没有columns属性
'#######################################################################################################################'

"""
基本数据分析实例
下面我们使用真正的股票数据构建DataFrame对象，来更深入的学习pandas的使用，
首先获得特斯拉电动车两年的股票数据，如下所示：
"""
from abupy import ABuSymbolPd
#n_folds=2 两年
tsla_df = ABuSymbolPd.make_kl_df('usTSLA',n_folds=2)
#前5列数据和后5列数据
print(tsla_df.head())
#              close    high     low  p_change    open  pre_close   volume  \
# 2016-05-17  204.66  209.82  204.02    -1.743  209.05     208.29  2843597
# 2016-05-18  211.17  215.31  207.75     3.181  209.15     204.66  5617519
# 2016-05-19  215.21  216.79  207.30     1.913  213.62     211.17  6866321
# 2016-05-20  220.28  220.55  216.35     2.356  216.99     215.21  9007076
# 2016-05-23  216.22  222.60  215.86    -1.843  219.87     220.28  5102479
#                 date  date_week   atr21   atr14  key
# 2016-05-17  20160517          1  5.8000  5.8000    0
# 2016-05-18  20160518          2  6.7219  6.7429    1
# 2016-05-19  20160519          3  8.6989  8.8008    2
# 2016-05-20  20160520          4  8.8942  8.9780    3
# 2016-05-23  20160523          0  8.5335  8.5637    4
print(tsla_df.tail())
#              close    high     low  p_change    open  pre_close   volume  \
# 2018-05-10  305.02  312.99  304.11    -0.596  307.50     306.85  5651561
# 2018-05-11  301.06  308.88  299.08    -1.298  307.70     305.02  4679649
# 2018-05-14  291.97  304.94  291.62    -3.019  303.32     301.06  7286804
# 2018-05-15  284.18  286.96  280.50    -2.668  285.01     291.97  9519173
# 2018-05-16  286.48  288.81  281.56     0.809  283.83     284.18  5674019
#                 date  date_week    atr21    atr14  key
# 2018-05-10  20180510          3  14.4147  13.8544  497
# 2018-05-11  20180511          4  13.9952  13.3138  498
# 2018-05-14  20180514          0  13.9410  13.3253  499
# 2018-05-15  20180515          1  14.5428  14.2900  500
# 2018-05-16  20180516          2  14.1671  13.7726  501

#总览数据分析：使用pandas的plot()函数来展示TSLA在统计周期内的大致情况
#tsla_df[['close','volume']]取两列，将volume放在subplot，颜色为红绿，打开网格
tsla_df[['close','volume']].plot(subplots=True,style=['r','g'],grid=True)
#得到的结果如图pandas-4所示
#类似的可以得到日k线，代码如下：
# tsla_df_day1 = tsla_df.cumsum()  #这里不能采用cumsum()方法，因为已经得到了日线数据而不是得到了日线涨跌幅
ABuMarketDrawing.plot_candle_stick(tsla_df.index,
                                   tsla_df['open'].values,
                                   tsla_df['high'].values,
                                   tsla_df['low'].values,
                                   tsla_df['close'].values,
                                   tsla_df['volume'].values,
                                   None,
                                   'tsla_stock',
                                   day_sum=False,html_bk=False,
                                   save=False
                                   )
# 结果如图tsla_day_candlestick所示
#DataFrame对象的info()方法可以查看数据是否有缺失以及各子数据的数据类型，示例如下：
tsla_df.info()
# <class 'pandas.core.frame.DataFrame'>
# DatetimeIndex: 500 entries, 2016-05-18 to 2018-05-16
# Data columns (total 12 columns):
# close        500 non-null float64
# high         500 non-null float64
# low          500 non-null float64
# p_change     500 non-null float64
# open         500 non-null float64
# pre_close    500 non-null float64
# volume       500 non-null int64
# date         500 non-null int64
# date_week    500 non-null int64
# key          500 non-null int64
# atr21        500 non-null float64
# atr14        500 non-null float64
# dtypes: float64(8), int64(4)
# memory usage: 50.8 KB

#pandas的DataFrame对象的describe()方法的用途是分别展示每组数据的统计信息，得到的结果如下：
tsla_df.describe()
#           close      high       low  p_change      open  pre_close  \
# count  500.0000  500.0000  500.0000  500.0000  500.0000   500.0000
# mean   281.8402  285.8764  277.5615    0.1025  281.7980   281.6557
# std     58.6983   59.6530   57.8062    2.3557   58.9770    58.7978
# min    181.4500  184.7300  178.1900  -10.4500  182.5100   181.4500
# 25%    223.0125  225.6425  220.6350   -1.1625  223.0925   222.8525
# 50%    300.2950  305.4195  294.3650    0.0250  299.6000   300.1650
# 75%    333.4350  339.6225  326.7150    1.5310  333.0825   333.4350
# max    384.6400  389.5700  379.3450    9.8530  386.6900   384.6400
#            volume        date  date_week       key     atr21     atr14
# count  5.0000e+02  5.0000e+02   500.0000  500.0000  500.0000  500.0000
# mean   5.4102e+06  2.0169e+07     2.0500  249.5000   11.1226   11.1665
# std    3.3386e+06  6.7545e+03     1.3941  144.4818    3.5448    3.7936
# min    9.9338e+04  2.0161e+07     0.0000    0.0000    4.9814    4.3789
# 25%    3.4918e+06  2.0161e+07     1.0000  124.7500    7.7781    7.7997
# 50%    4.8035e+06  2.0171e+07     2.0000  249.5000   11.2795   11.1202
# 75%    6.6692e+06  2.0171e+07     3.0000  374.2500   13.4863   13.3890
# max    2.3742e+07  2.0181e+07     4.0000  499.0000   22.7927   25.3166

'#######################################################################################################################'

"""
索引选取与切片选择
pandas也支持类似于numpy一样的切片操作，同时也可以直接使用列名、行名称，甚至组合使用，特点是需要使用loc或者iloc声明方式
使用loc和iloc配合行名称、列名称选取切片的示例如下所示：
"""
#2017-8-8至2017-8-18开盘价格序列
print(tsla_df.loc['2017-08-08':'2017-08-18','open'])
# 2017-08-08    357.53
# 2017-08-09    361.00
# 2017-08-10    361.60
# 2017-08-11    356.97
# 2017-08-14    364.63
# 2017-08-15    365.20
# 2017-08-16    363.00
# 2017-08-17    361.21
# 2017-08-18    352.91

#loc配合行名称，如果不传列名则默认获取所有列，示例如下：
#2017-8-8至2017-8-18所有序列
print(tsla_df.loc['2017-08-08':'2017-08-18'])
#              close    high     low  p_change    open  pre_close   volume  \
# 2017-08-08  365.22  368.58  357.40     2.830  357.53     355.17  7449837
# 2017-08-09  363.53  370.00  358.95    -0.463  361.00     365.22  6892096
# 2017-08-10  355.40  366.65  354.66    -2.236  361.60     363.53  7092858
# 2017-08-11  357.87  361.26  353.62     0.695  356.97     355.40  4365783
# 2017-08-14  363.80  367.66  362.60     1.657  364.63     357.87  4519186
# 2017-08-15  362.33  365.49  359.37    -0.404  365.20     363.80  3085088
# 2017-08-16  362.91  366.50  362.52     0.160  363.00     362.33  3413773
# 2017-08-17  351.92  363.30  351.59    -3.028  361.21     362.91  5027660
# 2017-08-18  347.46  354.00  345.80    -1.267  352.91     351.92  5408183
#                 date  date_week  key    atr21    atr14
# 2017-08-08  20170808          1  306  17.3829  18.0690
# 2017-08-09  20170809          2  307  17.1508  17.6371
# 2017-08-10  20170810          3  308  16.6817  16.8842
# 2017-08-11  20170811          4  309  16.0661  15.9543
# 2017-08-14  20170814          0  310  15.7201  15.4617
# 2017-08-15  20170815          1  311  14.9837  14.4162
# 2017-08-16  20170816          2  312  13.9834  13.0247
# 2017-08-17  20170817          3  313  13.7767  12.8494
# 2017-08-18  20170818          4  314  14.0797  13.4175
#2017-8-8至2017-8-18'close','high','low','open'列数据
#drop()方法的使用方法1、drop([1:8],axis=1)表示取第1到7列 2、drop(['close','high'],axis=1)
print(tsla_df.loc['2017-08-08':'2017-08-18','close':'open'].drop(['p_change'],axis=1))
#              close    high     low    open
# 2017-08-08  365.22  368.58  357.40  357.53
# 2017-08-09  363.53  370.00  358.95  361.00
# 2017-08-10  355.40  366.65  354.66  361.60
# 2017-08-11  357.87  361.26  353.62  356.97
# 2017-08-14  363.80  367.66  362.60  364.63
# 2017-08-15  362.33  365.49  359.37  365.20
# 2017-08-16  362.91  366.50  362.52  363.00
# 2017-08-17  351.92  363.30  351.59  361.21
# 2017-08-18  347.46  354.00  345.80  352.91

#混合切片
#指定一个列
print(tsla_df.close[0,3])
#通过组成一个列表选择多个列
print(tsla_df[['close','high','low']][0:3])
#              close    high     low
# 2016-05-18  211.17  215.31  207.75
# 2016-05-19  215.21  216.79  207.30
# 2016-05-20  220.28  220.55  216.35

'#######################################################################################################################'
"""
通过逻辑条件进行数据筛选
句法结构与numpy进行逻辑筛选的句法结构相似，通过以下代码筛选出涨跌幅大于8%的交易日数据：
"""

print(tsla_df[np.abs(tsla_df.p_change)>8])
#              close    high     low  p_change    open  pre_close    volume  \
# 2016-06-22  196.66  205.95  195.75   -10.450  199.47     219.61  23742414
# 2017-08-03  347.09  350.00  343.15     9.853  345.33     315.96  13535033
# 2018-02-08  315.23  348.62  314.60    -8.629  343.31     345.00  10314573
# 2018-03-27  279.18  304.27  277.18    -8.219  304.00     304.18  13872029
#                 date  date_week  key    atr21    atr14
# 2016-06-22  20160622          2   23  10.0662  10.5621
# 2017-08-03  20170803          3  303  16.2307  16.8122
# 2018-02-08  20180208          3  433  14.8257  16.1369
# 2018-03-27  20180327          1  465  15.8350  16.5426
#从上述结果可以看到Series对象本质就是一个numpy的nd.array对象，可以使用numpy的相应方法
"""
以下代码在筛选满足'涨跌幅大于8%的交易日'的条件的基础上，增加条件'交易成交量大于统计周期内的平均值的2.5倍'，
完成后筛选出的数据就是股票交易中常说的放量突破(当然可以有更加复杂的筛选条件，比如持续3天保持趋势等等)
"""
con = (np.abs(tsla_df.p_change)>8) & (tsla_df.volume > 2.5 * tsla_df.volume.mean())
print(tsla_df[con])
#              close    high     low  p_change    open  pre_close    volume  \
# 2016-06-22  196.66  205.95  195.75   -10.450  199.47     219.61  23742414
# 2017-08-03  347.09  350.00  343.15     9.853  345.33     315.96  13535033
# 2018-03-27  279.18  304.27  277.18    -8.219  304.00     304.18  13872029
#                 date  date_week  key    atr21    atr14
# 2016-06-22  20160622          2   23  10.0662  10.5621
# 2017-08-03  20170803          3  303  16.2307  16.8122
# 2018-03-27  20180327          1  465  15.8350  16.5426
'#######################################################################################################################'

"""
数据的转换与规整
1、数据序列值排序
以下代码对涨跌幅p_change进行排序，打印出跌幅最大的5个交易日：
"""
print(tsla_df.sort_index(by='p_change')[:5])
#              close    high     low  p_change    open  pre_close    volume  \
# 2016-06-22  196.66  205.95  195.75   -10.450  199.47     219.61  23742414
# 2018-02-08  315.23  348.62  314.60    -8.629  343.31     345.00  10314573
# 2018-03-27  279.18  304.27  277.18    -8.219  304.00     304.18  13872029
# 2018-03-28  257.78  268.68  252.10    -7.665  264.58     279.18  21001437
# 2017-07-05  327.09  347.24  326.33    -7.240  347.20     352.62  17046701
#                 date  date_week  key    atr21    atr14
# 2016-06-22  20160622          2   23  10.0662  10.5621
# 2018-02-08  20180208          3  433  14.8257  16.1369
# 2018-03-27  20180327          1  465  15.8350  16.5426
# 2018-03-28  20180328          2  466  19.1300  21.2809
# 2017-07-05  20170705          2  282  16.4302  17.6295
#可以看到输出结果时按照从小到大的顺序升序排列的，
#以下代码对涨跌幅p_change进行排序，通过ascending=False指定排序方式为降序排列，打印出涨幅最大的5个交易日
print(tsla_df.sort_index(by='p_change',ascending=False)[:5])
#              close    high     low  p_change    open  pre_close    volume  \
# 2017-08-03  347.09  350.00  343.15     9.853  345.33     315.96  13535033
# 2017-04-03  298.52  299.00  284.58     7.266  286.90     278.30  13888618
# 2018-04-04  286.94  288.37  252.00     7.255  252.78     267.53  19896746
# 2018-01-08  336.41  337.02  315.50     6.264  316.00     316.58   9859435
# 2018-04-05  304.25  305.96  289.25     6.033  289.67     286.94   1018347
#                 date  date_week  key    atr21    atr14
# 2017-08-03  20170803          3  303  16.2307  16.8122
# 2017-04-03  20170403          0  218  10.4112  10.7581
# 2018-04-04  20180404          2  470  21.2290  23.2991
# 2018-01-08  20180108          0  411  12.0265  12.3185
# 2018-04-05  20180405          3  471  22.7927  25.3166
